{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request # библиотеки для открытия url\n",
    "import urllib.error # классы исключения библиотеки urllib.request \n",
    "from datetime import date # библиотека даты и времени\n",
    "import re # библиотека регулярных выражений\n",
    "import csv # библиотека записи csv-файлах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.zakon.kz/news' # веб-страница парсинга\n",
    "proxy = {'https': 'https://185.212.128.43:3128'} # свободный прокси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# через бесконечный цикл запрос проходит через свободный прокси с обработкой исключений \n",
    "while True:\n",
    "    try:\n",
    "        proxy_support = urllib.request.ProxyHandler(proxy)\n",
    "        opener = urllib.request.build_opener(proxy_support)\n",
    "        urllib.request.install_opener(opener)\n",
    "        req = urllib.request.Request(url)\n",
    "        resp = urllib.request.urlopen(req)\n",
    "    except urllib.error.HTTPError:\n",
    "        continue\n",
    "    except urllib.error.URLError:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "respData = resp.read() # html-текст веб-страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "respData = respData.decode(\"utf-8\") # байтовый тип конвертируем в string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment_nums = re.findall(r'<span class=comm_num>(.*?)</span>',str(respData))\n",
    "paragraphs = re.findall(r'<a(.*?)</a>',str(respData)) # через рег. выражения находим все ссылки\n",
    "dates = re.findall(r'<span(.*?</span>)',str(respData)) # через рег. выражения находим все времена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:52\n",
      "08:28\n",
      "08:18\n",
      "07:48\n",
      "07:34\n",
      "07:10\n",
      "06:49\n",
      "06:28\n",
      "06:10\n",
      "02:13\n",
      "01:55\n",
      "01:44\n",
      "01:27\n",
      "01:02\n",
      "00:29\n",
      "00:17\n"
     ]
    }
   ],
   "source": [
    "# сохраняем в массив времена из dates\n",
    "pubDates = []\n",
    "for i in dates:\n",
    "    if i.__contains__('n3'):\n",
    "        pubDates.append(str(re.split(\">|<\",i)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0 # итерируемая переменная для вызова элементов pubDates\n",
    "f = open('zakon.csv','w',newline='',encoding=\"utf-8\") # открываем новый файл zakon.csv для записи с кодировкой utf-8\n",
    "writer = csv.writer(f,delimiter=',', # функция записи данных в файл\n",
    "           quoting=csv.QUOTE_MINIMAL)\n",
    "writer.writerow(['Заголовок','Текст','Дата публикации']) # записываем первую строку - названия столбцов\n",
    "\n",
    "# проходим через все ссылки\n",
    "for each in paragraphs:\n",
    "    if each.__contains__(\"html\") and each.__contains__(\"target='_blank\"): # открываем лишь ссылки на новостные страницы\n",
    "        head = re.split(\"/|>|'\",each)[8] # выбираем заголовок из ссылки\n",
    "        #link = \"https://www.zakon.kz/\"+re.split(\"/|>|'\",each)[6]\n",
    "        text = \"\"\n",
    "        # сохраняем весь текст в переменную text, на каждый запрос переходим через прокси\n",
    "        while True:\n",
    "            try:\n",
    "                proxy_support = urllib.request.ProxyHandler(proxy)\n",
    "                opener = urllib.request.build_opener(proxy_support)\n",
    "                urllib.request.install_opener(opener)\n",
    "                curReq = urllib.request.Request(\"https://www.zakon.kz/\"+re.split(\"/|>|'\",each)[6])\n",
    "                curResp = urllib.request.urlopen(curReq)\n",
    "            except urllib.error.HTTPError:\n",
    "                continue\n",
    "            except urllib.error.URLError:\n",
    "                continue\n",
    "            break\n",
    "        curRespData = curResp.read()\n",
    "        curRespData = curRespData.decode(\"utf-8\")\n",
    "        curParagraphs = re.findall('<p>(.*?)</p>',str(curRespData)) # находим текст в текстовых абзацах\n",
    "        # сохраняем каждый текст\n",
    "        for y in curParagraphs:\n",
    "            text += re.sub('<[^>]+>','',str(y)) # удаляем все ссылки и теги из текста\n",
    "            #print(re.sub('<[^>]+>','',str(y)))\n",
    "        writer.writerow([head,text,str(date.today())+\" \"+pubDates[iter]]) # записываем все получившиеся данные в следующую строку\n",
    "        iter+=1 # присваиваем +1 для перехода на следующую дату\n",
    "f.close() # закрываем файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze>requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
